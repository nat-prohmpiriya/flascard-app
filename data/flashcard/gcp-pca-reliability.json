{
  "version": "2.0",
  "exportedAt": "2024-12-31T12:00:00.000Z",
  "deck": {
    "name": "GCP PCA - Reliability & DR",
    "description": "Disaster Recovery, High Availability และ SRE principles สำหรับ GCP Professional Cloud Architect",
    "category": "devops",
    "tags": ["gcp", "certification", "pca", "reliability", "dr", "sre"],
    "sourceLang": "en",
    "targetLang": "th"
  },
  "cards": [
    {
      "vocab": "What are RPO and RTO, and how do they affect architecture?",
      "pronunciation": "RPO and RTO",
      "meaning": "RPO และ RTO คืออะไร และมีผลต่อ architecture อย่างไร?",
      "example": "RPO (Recovery Point Objective): Maximum acceptable data loss (time). Example: RPO 1 hour = can lose up to 1 hour of data. Affects: Backup frequency, replication strategy. RTO (Recovery Time Objective): Maximum acceptable downtime. Example: RTO 4 hours = must recover within 4 hours. Affects: DR strategy, failover automation. Trade-offs: Lower RPO/RTO = higher cost. Tiers: Critical (minutes RPO/RTO, active-active), Important (hours, warm standby), Standard (days, cold backup). Architecture impact: RPO 0 = synchronous replication (Spanner, regional Cloud SQL HA). RPO > 0 = async replication, backups. RTO low = automated failover, pre-provisioned resources. Exam tip: Match RPO/RTO to business requirements and cost constraints.",
      "exampleTranslation": "RPO (Recovery Point Objective): Maximum acceptable data loss (time) Example: RPO 1 hour = สูญเสีย data ได้ถึง 1 hour Affects: Backup frequency, replication strategy RTO (Recovery Time Objective): Maximum acceptable downtime Example: RTO 4 hours = ต้อง recover ภายใน 4 hours Affects: DR strategy, failover automation Trade-offs: Lower RPO/RTO = higher cost Tiers: Critical (minutes RPO/RTO, active-active), Important (hours, warm standby), Standard (days, cold backup) Architecture impact: RPO 0 = synchronous replication (Spanner, regional Cloud SQL HA) RPO > 0 = async replication, backups RTO low = automated failover, pre-provisioned resources Exam tip: Match RPO/RTO กับ business requirements และ cost constraints"
    },
    {
      "vocab": "What are the disaster recovery patterns on GCP?",
      "pronunciation": "DR Patterns",
      "meaning": "Disaster recovery patterns บน GCP มีอะไรบ้าง?",
      "example": "DR patterns (by cost/RTO): 1) Cold: Backup data only, rebuild infra on disaster. Lowest cost, highest RTO. 2) Warm (Pilot Light): Minimal infra running, scale up on disaster. Medium cost/RTO. 3) Warm (Standby): Reduced capacity always running. Higher cost, lower RTO. 4) Hot (Active-Active): Full capacity in multiple regions. Highest cost, lowest RTO. GCP implementations: Cold: Cloud Storage backups, Terraform for infra. Warm: Cloud SQL read replica (promote on disaster), minimal GKE cluster. Hot: Global LB, multi-region GKE, Spanner. Multi-region services: Cloud Storage (multi-region), Spanner, Firestore, BigQuery (cross-region). Exam tip: Match pattern to RPO/RTO requirements, know cost implications.",
      "exampleTranslation": "DR patterns (by cost/RTO): 1) Cold: Backup data only, rebuild infra on disaster Lowest cost, highest RTO 2) Warm (Pilot Light): Minimal infra running, scale up on disaster Medium cost/RTO 3) Warm (Standby): Reduced capacity always running Higher cost, lower RTO 4) Hot (Active-Active): Full capacity in multiple regions Highest cost, lowest RTO GCP implementations: Cold: Cloud Storage backups, Terraform สำหรับ infra Warm: Cloud SQL read replica (promote on disaster), minimal GKE cluster Hot: Global LB, multi-region GKE, Spanner Multi-region services: Cloud Storage (multi-region), Spanner, Firestore, BigQuery (cross-region) Exam tip: Match pattern กับ RPO/RTO requirements, รู้ cost implications"
    },
    {
      "vocab": "How do you design for high availability on GCP?",
      "pronunciation": "High Availability Design",
      "meaning": "ออกแบบสำหรับ high availability บน GCP อย่างไร?",
      "example": "HA strategies by layer: Compute: 1) Managed Instance Groups (MIG): Auto-healing, regional distribution. 2) GKE: Multi-zone cluster, pod anti-affinity. 3) Cloud Run: Multi-region with Global LB. Database: 1) Cloud SQL: Regional HA (standby in different zone). 2) Spanner: Multi-region configurations. 3) Firestore: Multi-region mode. Networking: 1) Global Load Balancer: Routes to healthy backends. 2) Health checks: Detect and route around failures. 3) CDN: Edge caching reduces origin load. Data: 1) Cloud Storage: Multi-region or dual-region. 2) Cross-region replication. Availability targets: 99.9% = 8.76 hours/year downtime. 99.99% = 52.56 minutes/year. 99.999% = 5.26 minutes/year. Exam tip: Know regional vs zonal resources, HA configurations per service.",
      "exampleTranslation": "HA strategies by layer: Compute: 1) Managed Instance Groups (MIG): Auto-healing, regional distribution 2) GKE: Multi-zone cluster, pod anti-affinity 3) Cloud Run: Multi-region กับ Global LB Database: 1) Cloud SQL: Regional HA (standby ใน different zone) 2) Spanner: Multi-region configurations 3) Firestore: Multi-region mode Networking: 1) Global Load Balancer: Routes ไป healthy backends 2) Health checks: Detect และ route around failures 3) CDN: Edge caching reduces origin load Data: 1) Cloud Storage: Multi-region หรือ dual-region 2) Cross-region replication Availability targets: 99.9% = 8.76 hours/year downtime 99.99% = 52.56 minutes/year 99.999% = 5.26 minutes/year Exam tip: รู้ regional vs zonal resources, HA configurations ต่อ service"
    },
    {
      "vocab": "What are SRE principles and how do they apply to GCP?",
      "pronunciation": "SRE Principles",
      "meaning": "SRE principles มีอะไร และ apply กับ GCP อย่างไร?",
      "example": "Core SRE principles: 1) SLIs/SLOs/SLAs: Measure and target reliability. 2) Error budgets: Balance reliability and velocity. 3) Toil elimination: Automate repetitive work. 4) Monitoring and alerting: Detect issues proactively. 5) Blameless postmortems: Learn from incidents. GCP tools for SRE: 1) Cloud Monitoring: Metrics, dashboards, alerts. 2) Service Monitoring: SLO tracking, burn rate alerts. 3) Cloud Trace: Distributed tracing. 4) Cloud Profiler: Performance analysis. 5) Error Reporting: Automatic error grouping. Error budget example: 99.9% SLO = 0.1% error budget = 43.2 min/month. Use error budget for releases, experiments. When exhausted, focus on reliability. Exam tip: Understand SLI/SLO/error budget relationship, toil reduction.",
      "exampleTranslation": "Core SRE principles: 1) SLIs/SLOs/SLAs: Measure และ target reliability 2) Error budgets: Balance reliability และ velocity 3) Toil elimination: Automate repetitive work 4) Monitoring and alerting: Detect issues proactively 5) Blameless postmortems: Learn from incidents GCP tools สำหรับ SRE: 1) Cloud Monitoring: Metrics, dashboards, alerts 2) Service Monitoring: SLO tracking, burn rate alerts 3) Cloud Trace: Distributed tracing 4) Cloud Profiler: Performance analysis 5) Error Reporting: Automatic error grouping Error budget example: 99.9% SLO = 0.1% error budget = 43.2 min/month ใช้ error budget สำหรับ releases, experiments เมื่อหมด, focus on reliability Exam tip: เข้าใจ SLI/SLO/error budget relationship, toil reduction"
    },
    {
      "vocab": "How do you implement capacity planning on GCP?",
      "pronunciation": "Capacity Planning",
      "meaning": "Implement capacity planning บน GCP อย่างไร?",
      "example": "Capacity planning steps: 1) Forecast demand: Historical data, business growth projections. 2) Define resource requirements: CPU, memory, storage, network. 3) Plan for peaks: Handle expected spikes. 4) Buffer for unexpected: 20-30% headroom. GCP tools: 1) Monitoring dashboards: Track utilization trends. 2) Recommender: Right-sizing suggestions. 3) Capacity Planner: Forecast and plan. Scaling strategies: 1) Vertical: Larger instances (limited). 2) Horizontal: More instances (preferred). 3) Autoscaling: Automatic based on metrics. Quotas: 1) Check and request quota increases early. 2) Different quotas per region. Cost considerations: Balance over-provisioning cost vs under-provisioning risk. Exam tip: Know autoscaling configurations, quota management, headroom planning.",
      "exampleTranslation": "Capacity planning steps: 1) Forecast demand: Historical data, business growth projections 2) Define resource requirements: CPU, memory, storage, network 3) Plan for peaks: Handle expected spikes 4) Buffer for unexpected: 20-30% headroom GCP tools: 1) Monitoring dashboards: Track utilization trends 2) Recommender: Right-sizing suggestions 3) Capacity Planner: Forecast และ plan Scaling strategies: 1) Vertical: Larger instances (limited) 2) Horizontal: More instances (preferred) 3) Autoscaling: Automatic based on metrics Quotas: 1) Check และ request quota increases early 2) Different quotas per region Cost considerations: Balance over-provisioning cost vs under-provisioning risk Exam tip: รู้ autoscaling configurations, quota management, headroom planning"
    },
    {
      "vocab": "How do you handle failure modes in distributed systems?",
      "pronunciation": "Failure Handling",
      "meaning": "จัดการ failure modes ใน distributed systems อย่างไร?",
      "example": "Common failure modes: 1) Zone failure: Single zone outage. 2) Region failure: Entire region outage (rare). 3) Service degradation: Partial functionality. 4) Network partition: Communication breakdown. 5) Cascading failure: One failure triggers others. Resilience patterns: 1) Retry with exponential backoff: Handle transient failures. 2) Circuit breaker: Prevent cascade failures. 3) Timeout: Don't wait forever. 4) Bulkhead: Isolate failures. 5) Graceful degradation: Reduce functionality vs complete failure. GCP implementations: 1) Global LB health checks: Route around failures. 2) Cloud Tasks: Reliable async with retry. 3) Pub/Sub: Decouple services. 4) Regional MIGs: Spread across zones. Testing: Chaos engineering, game days, fault injection. Exam tip: Know retry patterns, circuit breakers, designing for partial failures.",
      "exampleTranslation": "Common failure modes: 1) Zone failure: Single zone outage 2) Region failure: Entire region outage (rare) 3) Service degradation: Partial functionality 4) Network partition: Communication breakdown 5) Cascading failure: One failure triggers others Resilience patterns: 1) Retry with exponential backoff: Handle transient failures 2) Circuit breaker: Prevent cascade failures 3) Timeout: Don't wait forever 4) Bulkhead: Isolate failures 5) Graceful degradation: Reduce functionality vs complete failure GCP implementations: 1) Global LB health checks: Route around failures 2) Cloud Tasks: Reliable async กับ retry 3) Pub/Sub: Decouple services 4) Regional MIGs: Spread across zones Testing: Chaos engineering, game days, fault injection Exam tip: รู้ retry patterns, circuit breakers, designing for partial failures"
    },
    {
      "vocab": "How do you implement incident management?",
      "pronunciation": "Incident Management",
      "meaning": "Implement incident management อย่างไร?",
      "example": "Incident lifecycle: 1) Detection: Automated monitoring, alerts. 2) Response: Acknowledge, assess severity. 3) Mitigation: Stop the bleeding, workarounds. 4) Resolution: Fix root cause. 5) Postmortem: Learn and improve. Severity levels: SEV1 (critical, all hands), SEV2 (major, on-call team), SEV3 (minor, next business day). GCP tools: 1) Cloud Monitoring alerts: Detection. 2) PagerDuty/Opsgenie integration: On-call management. 3) Cloud Logging: Investigation. 4) Error Reporting: Error tracking. Postmortem best practices: 1) Blameless culture. 2) Timeline of events. 3) Root cause analysis. 4) Action items with owners. 5) Share learnings. Communication: Status pages, stakeholder updates, customer communication. Exam tip: Understand severity classification, postmortem process.",
      "exampleTranslation": "Incident lifecycle: 1) Detection: Automated monitoring, alerts 2) Response: Acknowledge, assess severity 3) Mitigation: Stop the bleeding, workarounds 4) Resolution: Fix root cause 5) Postmortem: Learn and improve Severity levels: SEV1 (critical, all hands), SEV2 (major, on-call team), SEV3 (minor, next business day) GCP tools: 1) Cloud Monitoring alerts: Detection 2) PagerDuty/Opsgenie integration: On-call management 3) Cloud Logging: Investigation 4) Error Reporting: Error tracking Postmortem best practices: 1) Blameless culture 2) Timeline of events 3) Root cause analysis 4) Action items with owners 5) Share learnings Communication: Status pages, stakeholder updates, customer communication Exam tip: เข้าใจ severity classification, postmortem process"
    },
    {
      "vocab": "What is chaos engineering and how do you implement it on GCP?",
      "pronunciation": "Chaos Engineering",
      "meaning": "Chaos engineering คืออะไร และ implement บน GCP อย่างไร?",
      "example": "Chaos engineering: Deliberately inject failures to test resilience. Principles: 1) Define steady state (normal behavior). 2) Hypothesize about impact. 3) Inject failure. 4) Observe and learn. 5) Minimize blast radius. Types of experiments: 1) Infrastructure: Kill VMs, zone failure simulation. 2) Network: Latency injection, packet loss. 3) Application: Error injection, dependency failure. 4) Resource: CPU/memory exhaustion. GCP implementation: 1) Managed Instance Groups: Simulate by deleting VMs. 2) Network: Traffic Director fault injection. 3) GKE: Pod disruption, network policies. 4) Load testing: Identify breaking points. Tools: Chaos Monkey (Netflix), Litmus, Gremlin, custom scripts. Best practices: Start small, have rollback plan, run in non-prod first. Exam tip: Understand chaos engineering principles, fault injection approaches.",
      "exampleTranslation": "Chaos engineering: Deliberately inject failures เพื่อ test resilience Principles: 1) Define steady state (normal behavior) 2) Hypothesize about impact 3) Inject failure 4) Observe และ learn 5) Minimize blast radius Types of experiments: 1) Infrastructure: Kill VMs, zone failure simulation 2) Network: Latency injection, packet loss 3) Application: Error injection, dependency failure 4) Resource: CPU/memory exhaustion GCP implementation: 1) Managed Instance Groups: Simulate โดย deleting VMs 2) Network: Traffic Director fault injection 3) GKE: Pod disruption, network policies 4) Load testing: Identify breaking points Tools: Chaos Monkey (Netflix), Litmus, Gremlin, custom scripts Best practices: Start small, มี rollback plan, run ใน non-prod ก่อน Exam tip: เข้าใจ chaos engineering principles, fault injection approaches"
    }
  ]
}
