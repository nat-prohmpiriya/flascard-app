{
  "version": "2.0",
  "exportedAt": "2025-01-01T00:00:00.000Z",
  "deck": {
    "name": "NLP & Language Models",
    "description": "Natural Language Processing, text processing, and language model terminology",
    "category": "Technical English",
    "sourceLang": "en",
    "targetLang": "th",
    "tags": ["english", "technical", "nlp", "language-models", "ai"]
  },
  "cards": [
    {
      "vocab": "natural language processing (NLP)",
      "pronunciation": "แนช-ชู-รอล แลง-กวิจ โปร-เซส-ซิง",
      "meaning": "การประมวลผลภาษาธรรมชาติ - ให้คอมเข้าใจภาษามนุษย์",
      "example": "NLP enables chatbots to understand human language.",
      "exampleTranslation": "NLP ทำให้ chatbot เข้าใจภาษามนุษย์"
    },
    {
      "vocab": "tokenization",
      "pronunciation": "โท-เค็น-ไน-เซ-ชัน",
      "meaning": "การแบ่ง token - ตัดข้อความเป็นชิ้นย่อย",
      "example": "Tokenization splits text into words or subwords.",
      "exampleTranslation": "Tokenization แบ่งข้อความเป็นคำหรือ subword"
    },
    {
      "vocab": "token",
      "pronunciation": "โท-เค็น",
      "meaning": "หน่วยย่อยของข้อความ - คำ, subword, หรือตัวอักษร",
      "example": "GPT-4 has a context window of 128K tokens.",
      "exampleTranslation": "GPT-4 มี context window 128K tokens"
    },
    {
      "vocab": "vocabulary",
      "pronunciation": "โว-แค็บ-ยู-ลา-รี่",
      "meaning": "คลังคำศัพท์ - รายการ token ทั้งหมดที่โมเดลรู้จัก",
      "example": "The model has a vocabulary of 50,000 tokens.",
      "exampleTranslation": "โมเดลมี vocabulary 50,000 tokens"
    },
    {
      "vocab": "embedding",
      "pronunciation": "เอ็ม-เบ็ด-ดิง",
      "meaning": "การฝัง - แปลงคำเป็น vector ตัวเลข",
      "example": "Word embeddings capture semantic relationships.",
      "exampleTranslation": "Word embedding จับความสัมพันธ์เชิงความหมาย"
    },
    {
      "vocab": "word2vec",
      "pronunciation": "เวิร์ด-ทู-เว็ค",
      "meaning": "อัลกอริทึมสร้าง word embedding แบบคลาสสิก",
      "example": "Word2Vec learns embeddings from context.",
      "exampleTranslation": "Word2Vec เรียน embedding จากบริบท"
    },
    {
      "vocab": "semantic similarity",
      "pronunciation": "เซ-แมน-ติค ซิ-มิ-ลา-ริ-ตี้",
      "meaning": "ความคล้ายเชิงความหมาย - คำที่มีความหมายใกล้กัน",
      "example": "King and queen have high semantic similarity.",
      "exampleTranslation": "King กับ queen มี semantic similarity สูง"
    },
    {
      "vocab": "cosine similarity",
      "pronunciation": "โค-ซายน์ ซิ-มิ-ลา-ริ-ตี้",
      "meaning": "ความคล้ายโคไซน์ - วัดมุมระหว่าง vector",
      "example": "Use cosine similarity to compare embeddings.",
      "exampleTranslation": "ใช้ cosine similarity เปรียบเทียบ embedding"
    },
    {
      "vocab": "BERT",
      "pronunciation": "เบิร์ท",
      "meaning": "Bidirectional Encoder Representations - โมเดลเข้าใจบริบทสองทิศ",
      "example": "BERT reads text bidirectionally for better understanding.",
      "exampleTranslation": "BERT อ่านข้อความสองทิศเพื่อเข้าใจดีขึ้น"
    },
    {
      "vocab": "GPT",
      "pronunciation": "จี-พี-ที",
      "meaning": "Generative Pre-trained Transformer - โมเดลสร้างข้อความ",
      "example": "GPT generates text by predicting the next token.",
      "exampleTranslation": "GPT สร้างข้อความโดยทำนาย token ถัดไป"
    },
    {
      "vocab": "pre-training",
      "pronunciation": "พรี-เทรน-นิง",
      "meaning": "การฝึกล่วงหน้า - เรียนจากข้อมูลขนาดใหญ่ก่อน",
      "example": "Pre-training on large corpora gives general knowledge.",
      "exampleTranslation": "Pre-training บน corpus ใหญ่ให้ความรู้ทั่วไป"
    },
    {
      "vocab": "fine-tuning",
      "pronunciation": "ไฟน์-ทูน-นิง",
      "meaning": "การปรับจูน - ฝึกต่อบนงานเฉพาะ",
      "example": "Fine-tune the model on your specific dataset.",
      "exampleTranslation": "Fine-tune โมเดลบน dataset เฉพาะของคุณ"
    },
    {
      "vocab": "transfer learning",
      "pronunciation": "ทรานส์-เฟอร์ เลิร์น-นิง",
      "meaning": "การเรียนรู้ถ่ายโอน - ใช้ความรู้จากงานหนึ่งไปอีกงาน",
      "example": "Transfer learning reduces training time significantly.",
      "exampleTranslation": "Transfer learning ลดเวลาฝึกได้มาก"
    },
    {
      "vocab": "masked language model",
      "pronunciation": "มาสค์ แลง-กวิจ โม-เดล",
      "meaning": "โมเดลภาษาแบบปิดบัง - ทายคำที่ถูกซ่อน",
      "example": "BERT uses masked language modeling for pre-training.",
      "exampleTranslation": "BERT ใช้ masked language modeling สำหรับ pre-training"
    },
    {
      "vocab": "causal language model",
      "pronunciation": "คอ-ซอล แลง-กวิจ โม-เดล",
      "meaning": "โมเดลภาษาเชิงเหตุ - ทายคำถัดไป",
      "example": "GPT is a causal language model predicting next tokens.",
      "exampleTranslation": "GPT เป็น causal language model ทำนาย token ถัดไป"
    },
    {
      "vocab": "sequence-to-sequence",
      "pronunciation": "ซี-เควนซ์-ทู-ซี-เควนซ์",
      "meaning": "ลำดับสู่ลำดับ - แปลง input sequence เป็น output sequence",
      "example": "Machine translation uses seq2seq models.",
      "exampleTranslation": "การแปลภาษาใช้โมเดล seq2seq"
    },
    {
      "vocab": "named entity recognition (NER)",
      "pronunciation": "เนมด์ เอ็น-ทิ-ตี้ เร-ค็อก-นิ-ชัน",
      "meaning": "การจดจำ entity - หาชื่อคน สถานที่ องค์กร",
      "example": "NER extracts names, dates, and locations from text.",
      "exampleTranslation": "NER ดึงชื่อ วันที่ และสถานที่จากข้อความ"
    },
    {
      "vocab": "sentiment analysis",
      "pronunciation": "เซน-ทิ-เมนท์ อะ-นา-ลิ-ซิส",
      "meaning": "การวิเคราะห์ความรู้สึก - บวก/ลบ/กลาง",
      "example": "Sentiment analysis classifies reviews as positive or negative.",
      "exampleTranslation": "Sentiment analysis จำแนกรีวิวว่าบวกหรือลบ"
    },
    {
      "vocab": "text classification",
      "pronunciation": "เท็กซ์ คลาส-ซิ-ฟิ-เค-ชัน",
      "meaning": "การจำแนกข้อความ - แบ่งหมวดหมู่ข้อความ",
      "example": "Spam detection is a text classification task.",
      "exampleTranslation": "การตรวจจับสแปมเป็นงาน text classification"
    },
    {
      "vocab": "question answering",
      "pronunciation": "เควส-ชัน อาน-เซอ-ริง",
      "meaning": "การตอบคำถาม - หาคำตอบจากข้อความ",
      "example": "QA systems extract answers from documents.",
      "exampleTranslation": "ระบบ QA ดึงคำตอบจากเอกสาร"
    },
    {
      "vocab": "text summarization",
      "pronunciation": "เท็กซ์ ซัม-มา-ไร-เซ-ชัน",
      "meaning": "การสรุปข้อความ - ย่อเนื้อหาสำคัญ",
      "example": "Summarization condenses long articles.",
      "exampleTranslation": "Summarization ย่อบทความยาว"
    },
    {
      "vocab": "machine translation",
      "pronunciation": "แมชชีน ทรานส์-เล-ชัน",
      "meaning": "การแปลภาษาด้วยเครื่อง - แปลอัตโนมัติ",
      "example": "Google Translate uses neural machine translation.",
      "exampleTranslation": "Google Translate ใช้ neural machine translation"
    },
    {
      "vocab": "beam search",
      "pronunciation": "บีม เซิร์ช",
      "meaning": "การค้นหาแบบลำแสง - เก็บหลาย candidates ขณะ decode",
      "example": "Beam search improves text generation quality.",
      "exampleTranslation": "Beam search ปรับปรุงคุณภาพการสร้างข้อความ"
    },
    {
      "vocab": "greedy decoding",
      "pronunciation": "กรี-ดี้ ดี-โค-ดิง",
      "meaning": "การถอดรหัสแบบโลภ - เลือก token ที่ดีสุดทุกขั้น",
      "example": "Greedy decoding is fast but may miss better outputs.",
      "exampleTranslation": "Greedy decoding เร็วแต่อาจพลาด output ที่ดีกว่า"
    },
    {
      "vocab": "perplexity",
      "pronunciation": "เพอร์-เพล็ก-ซิ-ตี้",
      "meaning": "ความงุนงง - วัดว่าโมเดลมั่นใจแค่ไหน (ยิ่งต่ำยิ่งดี)",
      "example": "Lower perplexity indicates a better language model.",
      "exampleTranslation": "Perplexity ต่ำบ่งบอกว่าโมเดลภาษาดีกว่า"
    },
    {
      "vocab": "BLEU score",
      "pronunciation": "บลู สกอร์",
      "meaning": "คะแนนวัดคุณภาพการแปล - เทียบกับ reference",
      "example": "BLEU measures translation quality against references.",
      "exampleTranslation": "BLEU วัดคุณภาพการแปลเทียบกับ reference"
    },
    {
      "vocab": "stop words",
      "pronunciation": "สต็อป เวิร์ดส์",
      "meaning": "คำหยุด - คำทั่วไปที่มักตัดออก (the, a, is)",
      "example": "Remove stop words to reduce noise in analysis.",
      "exampleTranslation": "ลบ stop words เพื่อลด noise ในการวิเคราะห์"
    },
    {
      "vocab": "stemming",
      "pronunciation": "สเต็ม-มิง",
      "meaning": "การตัดรากคำ - ตัด suffix ออก (running → run)",
      "example": "Stemming reduces words to their root form.",
      "exampleTranslation": "Stemming ลดคำให้เหลือรูปราก"
    },
    {
      "vocab": "lemmatization",
      "pronunciation": "เล็ม-มา-ไท-เซ-ชัน",
      "meaning": "การหารากศัพท์ - หา lemma ที่ถูกต้อง (better → good)",
      "example": "Lemmatization returns the dictionary form of words.",
      "exampleTranslation": "Lemmatization คืนรูปพจนานุกรมของคำ"
    },
    {
      "vocab": "corpus",
      "pronunciation": "คอร์-พัส",
      "meaning": "คลังข้อความ - ชุดเอกสารสำหรับฝึกโมเดล",
      "example": "Train the model on a large corpus of text.",
      "exampleTranslation": "ฝึกโมเดลบน corpus ข้อความขนาดใหญ่"
    }
  ]
}
