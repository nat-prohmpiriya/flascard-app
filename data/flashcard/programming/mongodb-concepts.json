{
  "version": "2.0",
  "exportedAt": "2024-12-28T12:00:00.000Z",
  "deck": {
    "name": "MongoDB Concepts",
    "description": "Core MongoDB concepts including documents, queries, aggregation, indexing, schema design, and clustering",
    "category": "Database",
    "tags": ["mongodb", "nosql", "database", "concepts"],
    "sourceLang": "en",
    "targetLang": "th"
  },
  "cards": [
    {
      "vocab": "What is MongoDB and when to use it?",
      "pronunciation": "// Document-oriented NoSQL database\n// Stores data as BSON (Binary JSON)\n\n// Use cases:\n- Flexible schema / evolving data\n- Large volumes of data\n- High write throughput\n- Geospatial data\n- Real-time analytics\n- Content management\n- IoT data\n- Catalogs / product data",
      "meaning": "MongoDB คืออะไรและใช้เมื่อไหร่?",
      "example": "MongoDB is a document-oriented NoSQL database storing data as flexible JSON-like documents (BSON). No fixed schema - each document can have different fields. Horizontal scaling via sharding. Best for: flexible/evolving schemas, high write loads, hierarchical data, rapid development. Not ideal for complex transactions across documents.",
      "exampleTranslation": "MongoDB คือ document-oriented NoSQL database ที่เก็บ data เป็น flexible JSON-like documents (BSON) ไม่มี fixed schema - แต่ละ document มี fields ต่างกันได้ Horizontal scaling ผ่าน sharding ดีที่สุดสำหรับ: flexible/evolving schemas, high write loads, hierarchical data, rapid development ไม่เหมาะสำหรับ complex transactions ข้าม documents"
    },
    {
      "vocab": "What is BSON and how does it differ from JSON?",
      "pronunciation": "// JSON (JavaScript Object Notation)\n{\"name\": \"John\", \"age\": 30}\n\n// BSON (Binary JSON) - MongoDB's format\n// Additional types:\nObjectId(\"507f1f77bcf86cd799439011\")\nISODate(\"2024-01-15T10:30:00Z\")\nNumberLong(9223372036854775807)\nBinData(0, \"base64data\")\nDecimal128(\"9.99\")\n\n// BSON advantages:\n// - More data types\n// - Binary format (faster parsing)\n// - Length-prefixed (efficient traversal)\n// - Supports embedded documents",
      "meaning": "BSON คืออะไรและต่างจาก JSON อย่างไร?",
      "example": "BSON is Binary JSON - MongoDB's internal format. Extends JSON with additional types: ObjectId, Date, Binary, Decimal128, int64, etc. Binary format enables faster parsing and efficient storage. Length-prefixed strings allow skipping fields. Trade-off: slightly larger than JSON due to type and length info.",
      "exampleTranslation": "BSON คือ Binary JSON - format ภายในของ MongoDB ขยาย JSON ด้วย types เพิ่มเติม: ObjectId, Date, Binary, Decimal128, int64 เป็นต้น Binary format ทำให้ parsing เร็วขึ้นและ storage มีประสิทธิภาพ Length-prefixed strings อนุญาตให้ข้าม fields ได้ Trade-off: ใหญ่กว่า JSON เล็กน้อยเพราะ type และ length info"
    },
    {
      "vocab": "What is ObjectId?",
      "pronunciation": "// ObjectId - 12 bytes unique identifier\nObjectId(\"507f1f77bcf86cd799439011\")\n\n// Structure (12 bytes):\n// - 4 bytes: Unix timestamp\n// - 5 bytes: random value (machine + process)\n// - 3 bytes: incrementing counter\n\n// Get timestamp from ObjectId\nObjectId(\"507f1f77bcf86cd799439011\").getTimestamp()\n// ISODate(\"2012-10-17T20:46:22Z\")\n\n// Create new ObjectId\nnew ObjectId()  // auto-generated\nObjectId()      // same\n\n// Compare ObjectIds (time-based sorting)\n// Older ObjectIds are \"less than\" newer ones",
      "meaning": "ObjectId คืออะไร?",
      "example": "ObjectId is MongoDB's default 12-byte unique identifier for documents. Contains: 4-byte timestamp + 5-byte random + 3-byte counter. Automatically generated for _id field if not provided. Roughly sortable by creation time. Can extract timestamp with getTimestamp(). Unique across collections, databases, and servers.",
      "exampleTranslation": "ObjectId คือ 12-byte unique identifier เริ่มต้นของ MongoDB สำหรับ documents ประกอบด้วย: 4-byte timestamp + 5-byte random + 3-byte counter สร้างอัตโนมัติสำหรับ _id field ถ้าไม่ได้ระบุ sort ตาม creation time ได้คร่าวๆ ดึง timestamp ได้ด้วย getTimestamp() Unique ข้าม collections, databases และ servers"
    },
    {
      "vocab": "What are the basic CRUD operations in MongoDB?",
      "pronunciation": "// CREATE\ndb.users.insertOne({name: \"John\", age: 30})\ndb.users.insertMany([{name: \"Jane\"}, {name: \"Bob\"}])\n\n// READ\ndb.users.findOne({name: \"John\"})\ndb.users.find({age: {$gte: 18}})\ndb.users.find().limit(10).skip(20).sort({name: 1})\n\n// UPDATE\ndb.users.updateOne(\n  {name: \"John\"},\n  {$set: {age: 31}}\n)\ndb.users.updateMany(\n  {status: \"active\"},\n  {$inc: {visits: 1}}\n)\ndb.users.replaceOne({name: \"John\"}, {name: \"John\", age: 32})\n\n// DELETE\ndb.users.deleteOne({name: \"John\"})\ndb.users.deleteMany({status: \"inactive\"})",
      "meaning": "MongoDB มี CRUD operations พื้นฐานอะไรบ้าง?",
      "example": "Create: insertOne/insertMany. Read: findOne/find with query filters. Update: updateOne/updateMany with update operators ($set, $inc, etc.) or replaceOne for full replacement. Delete: deleteOne/deleteMany. All operations return result objects with counts. Use filters to target specific documents.",
      "exampleTranslation": "Create: insertOne/insertMany Read: findOne/find กับ query filters Update: updateOne/updateMany กับ update operators ($set, $inc เป็นต้น) หรือ replaceOne สำหรับ replacement ทั้งหมด Delete: deleteOne/deleteMany ทุก operations return result objects พร้อม counts ใช้ filters เพื่อเจาะจง documents"
    },
    {
      "vocab": "What are query operators in MongoDB?",
      "pronunciation": "// Comparison\n{age: {$eq: 30}}      // equal\n{age: {$ne: 30}}      // not equal\n{age: {$gt: 18}}      // greater than\n{age: {$gte: 18}}     // greater than or equal\n{age: {$lt: 65}}      // less than\n{age: {$in: [20, 30, 40]}}  // in array\n{age: {$nin: [20, 30]}}     // not in array\n\n// Logical\n{$and: [{age: {$gte: 18}}, {status: \"active\"}]}\n{$or: [{status: \"active\"}, {role: \"admin\"}]}\n{$not: {age: {$lt: 18}}}\n{$nor: [{status: \"banned\"}, {role: \"guest\"}]}\n\n// Element\n{email: {$exists: true}}   // field exists\n{age: {$type: \"number\"}}   // field type\n\n// Array\n{tags: {$all: [\"a\", \"b\"]}}  // contains all\n{scores: {$elemMatch: {$gte: 80, $lt: 90}}}\n{tags: {$size: 3}}          // array length",
      "meaning": "MongoDB มี query operators อะไรบ้าง?",
      "example": "Comparison: $eq, $ne, $gt, $gte, $lt, $lte, $in, $nin. Logical: $and, $or, $not, $nor. Element: $exists, $type. Array: $all, $elemMatch, $size. Regex: $regex. Implicit $and when multiple conditions on same level. $elemMatch matches single array element meeting all conditions.",
      "exampleTranslation": "Comparison: $eq, $ne, $gt, $gte, $lt, $lte, $in, $nin Logical: $and, $or, $not, $nor Element: $exists, $type Array: $all, $elemMatch, $size Regex: $regex Implicit $and เมื่อหลาย conditions อยู่ level เดียวกัน $elemMatch match single array element ที่ตรง conditions ทั้งหมด"
    },
    {
      "vocab": "What are update operators in MongoDB?",
      "pronunciation": "// Field operators\n{$set: {name: \"John\"}}       // set field value\n{$unset: {temp: \"\"}}         // remove field\n{$inc: {count: 1}}           // increment\n{$mul: {price: 1.1}}         // multiply\n{$min: {low: 5}}             // update if less\n{$max: {high: 10}}           // update if greater\n{$rename: {old: \"new\"}}      // rename field\n{$setOnInsert: {created: new Date()}}  // only on upsert\n\n// Array operators\n{$push: {tags: \"new\"}}       // add to array\n{$push: {tags: {$each: [\"a\", \"b\"]}}}  // add multiple\n{$addToSet: {tags: \"unique\"}}  // add if not exists\n{$pop: {arr: 1}}             // remove last (-1 for first)\n{$pull: {tags: \"remove\"}}    // remove matching\n{$pullAll: {tags: [\"a\", \"b\"]}}  // remove all matching\n\n// Array with position\n{$set: {\"scores.0\": 100}}    // by index\n{$set: {\"scores.$\": 100}}    // matched element\n{$set: {\"scores.$[]\": 0}}    // all elements\n{$set: {\"scores.$[elem]\": 0}}  // filtered",
      "meaning": "MongoDB มี update operators อะไรบ้าง?",
      "example": "Field: $set, $unset, $inc, $mul, $min, $max, $rename, $setOnInsert. Array: $push, $addToSet, $pop, $pull, $pullAll. With $each for multiple values, $slice to limit, $sort to order. Position: $ for matched element, $[] for all, $[identifier] with arrayFilters for conditional updates.",
      "exampleTranslation": "Field: $set, $unset, $inc, $mul, $min, $max, $rename, $setOnInsert Array: $push, $addToSet, $pop, $pull, $pullAll กับ $each สำหรับหลายค่า $slice เพื่อจำกัด $sort เพื่อเรียง Position: $ สำหรับ matched element, $[] สำหรับทั้งหมด $[identifier] กับ arrayFilters สำหรับ conditional updates"
    },
    {
      "vocab": "What is the aggregation pipeline?",
      "pronunciation": "db.orders.aggregate([\n  // Stage 1: Filter\n  {$match: {status: \"completed\"}},\n  \n  // Stage 2: Group and calculate\n  {$group: {\n    _id: \"$customerId\",\n    totalAmount: {$sum: \"$amount\"},\n    orderCount: {$sum: 1}\n  }},\n  \n  // Stage 3: Sort\n  {$sort: {totalAmount: -1}},\n  \n  // Stage 4: Limit\n  {$limit: 10},\n  \n  // Stage 5: Reshape output\n  {$project: {\n    customerId: \"$_id\",\n    totalAmount: 1,\n    orderCount: 1,\n    _id: 0\n  }}\n])",
      "meaning": "Aggregation pipeline คืออะไร?",
      "example": "Aggregation pipeline processes documents through stages. Each stage transforms documents and passes to next. Common stages: $match (filter), $group (aggregate), $sort, $project (reshape), $limit, $skip, $lookup (join), $unwind (flatten arrays). Documents flow left to right. Put $match early for performance.",
      "exampleTranslation": "Aggregation pipeline ประมวลผล documents ผ่าน stages แต่ละ stage transform documents และส่งต่อไปยังถัดไป Stages ที่ใช้บ่อย: $match (filter), $group (aggregate), $sort, $project (reshape), $limit, $skip, $lookup (join), $unwind (flatten arrays) Documents ไหลจากซ้ายไปขวา ใส่ $match ก่อนเพื่อ performance"
    },
    {
      "vocab": "What are common aggregation stages?",
      "pronunciation": "// $match - filter documents\n{$match: {status: \"active\", age: {$gte: 18}}}\n\n// $group - group and aggregate\n{$group: {\n  _id: \"$category\",\n  total: {$sum: \"$amount\"},\n  avg: {$avg: \"$price\"},\n  count: {$sum: 1},\n  items: {$push: \"$name\"}\n}}\n\n// $project - reshape/include/exclude fields\n{$project: {name: 1, _id: 0, fullName: {$concat: [\"$first\", \" \", \"$last\"]}}}\n\n// $lookup - join with another collection\n{$lookup: {\n  from: \"products\",\n  localField: \"productId\",\n  foreignField: \"_id\",\n  as: \"productDetails\"\n}}\n\n// $unwind - flatten array\n{$unwind: \"$items\"}\n\n// $addFields - add computed fields\n{$addFields: {totalPrice: {$multiply: [\"$price\", \"$quantity\"]}}}",
      "meaning": "Aggregation stages ที่ใช้บ่อยมีอะไรบ้าง?",
      "example": "$match filters documents. $group aggregates with accumulators ($sum, $avg, $min, $max, $push, $first, $last). $project includes/excludes/computes fields. $lookup joins collections. $unwind deconstructs arrays to documents. $addFields adds new fields. $sort, $limit, $skip for ordering and pagination.",
      "exampleTranslation": "$match filter documents $group aggregate ด้วย accumulators ($sum, $avg, $min, $max, $push, $first, $last) $project include/exclude/compute fields $lookup join collections $unwind deconstruct arrays เป็น documents $addFields เพิ่ม fields ใหม่ $sort, $limit, $skip สำหรับ ordering และ pagination"
    },
    {
      "vocab": "What is $lookup (join) in MongoDB?",
      "pronunciation": "// Basic lookup\ndb.orders.aggregate([\n  {$lookup: {\n    from: \"customers\",        // collection to join\n    localField: \"customerId\", // field in orders\n    foreignField: \"_id\",      // field in customers\n    as: \"customer\"            // output array field\n  }},\n  {$unwind: \"$customer\"}  // flatten array to object\n])\n\n// Pipeline lookup (more flexible)\ndb.orders.aggregate([\n  {$lookup: {\n    from: \"products\",\n    let: {productIds: \"$items.productId\"},\n    pipeline: [\n      {$match: {$expr: {$in: [\"$_id\", \"$$productIds\"]}}},\n      {$project: {name: 1, price: 1}}\n    ],\n    as: \"products\"\n  }}\n])\n\n// Uncorrelated subquery\n{$lookup: {\n  from: \"settings\",\n  pipeline: [{$match: {type: \"default\"}}],\n  as: \"settings\"\n}}",
      "meaning": "$lookup (join) ใน MongoDB คืออะไร?",
      "example": "$lookup performs left outer join with another collection. Basic form matches localField to foreignField. Result is array in 'as' field - use $unwind to flatten. Pipeline form allows complex conditions and transformations. Use let to pass variables to pipeline. Essential for denormalizing at query time.",
      "exampleTranslation": "$lookup ทำ left outer join กับ collection อื่น Form พื้นฐาน match localField กับ foreignField ผลลัพธ์เป็น array ใน 'as' field - ใช้ $unwind เพื่อ flatten Pipeline form อนุญาต complex conditions และ transformations ใช้ let เพื่อส่ง variables ไปยัง pipeline จำเป็นสำหรับ denormalizing ตอน query"
    },
    {
      "vocab": "What are the types of indexes in MongoDB?",
      "pronunciation": "// Single field index\ndb.users.createIndex({email: 1})  // ascending\ndb.users.createIndex({age: -1})   // descending\n\n// Compound index\ndb.orders.createIndex({customerId: 1, createdAt: -1})\n\n// Multikey index (arrays)\ndb.products.createIndex({tags: 1})  // auto for array fields\n\n// Text index (full-text search)\ndb.articles.createIndex({title: \"text\", content: \"text\"})\ndb.articles.find({$text: {$search: \"mongodb tutorial\"}})\n\n// Geospatial index\ndb.places.createIndex({location: \"2dsphere\"})\n\n// Hashed index (for sharding)\ndb.users.createIndex({userId: \"hashed\"})\n\n// TTL index (auto-expire documents)\ndb.sessions.createIndex({createdAt: 1}, {expireAfterSeconds: 3600})\n\n// Unique index\ndb.users.createIndex({email: 1}, {unique: true})\n\n// Partial index\ndb.orders.createIndex({status: 1}, {partialFilterExpression: {status: \"active\"}})",
      "meaning": "MongoDB มี indexes ประเภทอะไรบ้าง?",
      "example": "Single field for one field. Compound for multiple fields (order matters). Multikey auto-indexes arrays. Text for full-text search. 2dsphere for geospatial. Hashed for sharding. TTL auto-expires documents. Options: unique, sparse, partial. Compound index can support queries on prefix fields.",
      "exampleTranslation": "Single field สำหรับ field เดียว Compound สำหรับหลาย fields (ลำดับสำคัญ) Multikey auto-index arrays Text สำหรับ full-text search 2dsphere สำหรับ geospatial Hashed สำหรับ sharding TTL auto-expire documents Options: unique, sparse, partial Compound index รองรับ queries บน prefix fields ได้"
    },
    {
      "vocab": "What is the ESR rule for compound indexes?",
      "pronunciation": "// ESR = Equality, Sort, Range\n// Order fields in compound index by:\n\n// 1. Equality fields first (exact match)\n{status: \"active\", category: \"electronics\"}\n\n// 2. Sort fields second\n.sort({createdAt: -1})\n\n// 3. Range fields last\n{price: {$gte: 100, $lte: 500}}\n\n// Optimal index for this query:\ndb.products.createIndex({\n  status: 1,      // E: equality\n  category: 1,    // E: equality\n  createdAt: -1,  // S: sort\n  price: 1        // R: range\n})\n\n// Query:\ndb.products.find({\n  status: \"active\",\n  category: \"electronics\",\n  price: {$gte: 100, $lte: 500}\n}).sort({createdAt: -1})",
      "meaning": "ESR rule สำหรับ compound indexes คืออะไร?",
      "example": "ESR rule optimizes compound index field order: Equality first (exact matches), Sort second (order by), Range last (inequalities). This order maximizes index efficiency. Equality conditions filter most precisely, then sort uses index order, range conditions come last. Violating order causes index scans or in-memory sorts.",
      "exampleTranslation": "ESR rule optimize ลำดับ fields ใน compound index: Equality ก่อน (exact matches), Sort ที่สอง (order by), Range สุดท้าย (inequalities) ลำดับนี้ maximize index efficiency Equality conditions filter แม่นยำที่สุด แล้ว sort ใช้ index order range conditions มาสุดท้าย ไม่ทำตามลำดับทำให้เกิด index scans หรือ in-memory sorts"
    },
    {
      "vocab": "What is explain() and how to read query plans?",
      "pronunciation": "// Get query execution plan\ndb.users.find({email: \"test@example.com\"}).explain()\ndb.users.find({email: \"test@example.com\"}).explain(\"executionStats\")\n\n// Key fields to look for:\n{\n  \"queryPlanner\": {\n    \"winningPlan\": {\n      \"stage\": \"FETCH\",        // final stage\n      \"inputStage\": {\n        \"stage\": \"IXSCAN\",     // index scan (good)\n        \"indexName\": \"email_1\"\n      }\n    }\n  },\n  \"executionStats\": {\n    \"totalDocsExamined\": 1,   // docs looked at\n    \"totalKeysExamined\": 1,   // index entries\n    \"nReturned\": 1,           // docs returned\n    \"executionTimeMillis\": 0\n  }\n}\n\n// Bad signs:\n// - \"COLLSCAN\" (full collection scan)\n// - totalDocsExamined >> nReturned\n// - \"SORT\" stage (in-memory sort)",
      "meaning": "explain() และการอ่าน query plans ทำอย่างไร?",
      "example": "explain() shows query execution plan. Use 'executionStats' for actual metrics. Good signs: IXSCAN (index scan), low docsExamined/nReturned ratio. Bad signs: COLLSCAN (no index), SORT stage (in-memory), high examined vs returned ratio. Use to verify indexes are being used and optimize queries.",
      "exampleTranslation": "explain() แสดง query execution plan ใช้ 'executionStats' สำหรับ metrics จริง สัญญาณดี: IXSCAN (index scan), docsExamined/nReturned ratio ต่ำ สัญญาณไม่ดี: COLLSCAN (ไม่มี index), SORT stage (in-memory), examined vs returned ratio สูง ใช้เพื่อยืนยันว่า indexes ถูกใช้และ optimize queries"
    },
    {
      "vocab": "What is embedding vs referencing in schema design?",
      "pronunciation": "// Embedding (denormalized)\n{\n  _id: ObjectId(\"...\"),\n  name: \"John\",\n  address: {              // embedded document\n    street: \"123 Main St\",\n    city: \"NYC\"\n  },\n  orders: [               // embedded array\n    {product: \"Phone\", price: 999},\n    {product: \"Case\", price: 29}\n  ]\n}\n\n// Referencing (normalized)\n// users collection\n{_id: ObjectId(\"user1\"), name: \"John\"}\n\n// orders collection\n{\n  _id: ObjectId(\"order1\"),\n  userId: ObjectId(\"user1\"),  // reference\n  product: \"Phone\",\n  price: 999\n}\n\n// Hybrid approach\n{\n  name: \"John\",\n  recentOrders: [{...}, {...}],  // embed recent\n  orderCount: 150                 // denormalize count\n}",
      "meaning": "Embedding vs referencing ใน schema design คืออะไร?",
      "example": "Embedding: nested documents in parent. Pros: single query, atomic updates, data locality. Cons: document size limit (16MB), data duplication. Referencing: separate collections with IDs. Pros: no duplication, no size limit. Cons: multiple queries ($lookup). Embed for: 1-to-few, always accessed together. Reference for: 1-to-many, independent access.",
      "exampleTranslation": "Embedding: nested documents ใน parent ข้อดี: single query, atomic updates, data locality ข้อเสีย: document size limit (16MB), data duplication Referencing: collections แยกกับ IDs ข้อดี: ไม่มี duplication, ไม่มี size limit ข้อเสีย: multiple queries ($lookup) Embed สำหรับ: 1-to-few เข้าถึงด้วยกันเสมอ Reference สำหรับ: 1-to-many เข้าถึงแยกกัน"
    },
    {
      "vocab": "What are schema design patterns in MongoDB?",
      "pronunciation": "// 1. Subset Pattern - embed subset of large array\n{\n  name: \"Product\",\n  recentReviews: [{...}, {...}],  // last 10\n  totalReviews: 1500\n}\n\n// 2. Computed Pattern - store computed values\n{\n  name: \"Product\",\n  ratings: [5, 4, 5, 3],\n  avgRating: 4.25,         // pre-computed\n  totalRatings: 4\n}\n\n// 3. Bucket Pattern - group time-series data\n{\n  sensorId: \"sensor1\",\n  date: ISODate(\"2024-01-15\"),\n  readings: [              // hourly buckets\n    {hour: 0, value: 23.5},\n    {hour: 1, value: 24.0}\n  ]\n}\n\n// 4. Extended Reference - embed frequently accessed fields\n{\n  orderId: \"...\",\n  customer: {\n    _id: ObjectId(\"...\"),\n    name: \"John\",          // denormalized\n    email: \"john@...\"      // denormalized\n  }\n}",
      "meaning": "Schema design patterns ใน MongoDB มีอะไรบ้าง?",
      "example": "Subset: embed limited recent items, reference full list. Computed: pre-calculate aggregations (avg, sum). Bucket: group time-series data to reduce document count. Extended Reference: embed frequently-accessed fields from related docs. Polymorphic: different shapes in same collection. Choose based on query patterns and update frequency.",
      "exampleTranslation": "Subset: embed รายการล่าสุดจำกัด reference list เต็ม Computed: คำนวณ aggregations ล่วงหน้า (avg, sum) Bucket: group time-series data เพื่อลดจำนวน documents Extended Reference: embed fields ที่เข้าถึงบ่อยจาก related docs Polymorphic: shapes ต่างกันใน collection เดียว เลือกตาม query patterns และ update frequency"
    },
    {
      "vocab": "What is the 16MB document size limit?",
      "pronunciation": "// Document max size: 16 megabytes\n\n// Problem: Unbounded arrays\n{\n  _id: \"popular_post\",\n  comments: [...]  // can grow to millions!\n}\n\n// Solution 1: Reference instead of embed\n// comments collection\n{postId: \"popular_post\", text: \"...\", author: \"...\"}\n\n// Solution 2: Bucket pattern\n{\n  postId: \"popular_post\",\n  page: 1,\n  comments: [/* 100 comments */]\n}\n\n// Solution 3: Subset pattern\n{\n  _id: \"popular_post\",\n  recentComments: [/* last 10 */],\n  commentCount: 50000\n}\n\n// Check document size\nObject.bsonsize(db.collection.findOne({_id: \"...\"}))  // bytes",
      "meaning": "16MB document size limit คืออะไร?",
      "example": "MongoDB limits documents to 16MB BSON. Main cause: unbounded arrays that grow indefinitely. Solutions: 1) Reference in separate collection, 2) Bucket pattern to split into multiple documents, 3) Subset pattern with recent items only. Design schema to prevent unbounded growth. Use Object.bsonsize() to check.",
      "exampleTranslation": "MongoDB จำกัด documents ที่ 16MB BSON สาเหตุหลัก: unbounded arrays ที่โตไม่หยุด Solutions: 1) Reference ใน collection แยก 2) Bucket pattern แบ่งเป็นหลาย documents 3) Subset pattern กับ recent items เท่านั้น ออกแบบ schema เพื่อป้องกัน unbounded growth ใช้ Object.bsonsize() เพื่อ check"
    },
    {
      "vocab": "What are transactions in MongoDB?",
      "pronunciation": "// Single document operations are atomic by default\n\n// Multi-document transactions (MongoDB 4.0+)\nconst session = client.startSession();\n\ntry {\n  session.startTransaction();\n  \n  await users.updateOne(\n    {_id: userId},\n    {$inc: {balance: -100}},\n    {session}\n  );\n  \n  await transfers.insertOne(\n    {from: userId, to: recipientId, amount: 100},\n    {session}\n  );\n  \n  await users.updateOne(\n    {_id: recipientId},\n    {$inc: {balance: 100}},\n    {session}\n  );\n  \n  await session.commitTransaction();\n} catch (error) {\n  await session.abortTransaction();\n  throw error;\n} finally {\n  session.endSession();\n}",
      "meaning": "Transactions ใน MongoDB คืออะไร?",
      "example": "Single document operations are always atomic. Multi-document transactions (4.0+) ensure ACID across multiple documents and collections. Require replica set or sharded cluster. Use session to group operations. commitTransaction() saves, abortTransaction() rolls back. Transactions have performance cost - design schema to minimize need.",
      "exampleTranslation": "Single document operations เป็น atomic เสมอ Multi-document transactions (4.0+) รับประกัน ACID ข้ามหลาย documents และ collections ต้อง replica set หรือ sharded cluster ใช้ session เพื่อ group operations commitTransaction() บันทึก abortTransaction() rollback Transactions มี performance cost - ออกแบบ schema เพื่อลดความจำเป็น"
    },
    {
      "vocab": "What is a replica set?",
      "pronunciation": "// Replica set: group of mongod instances\n// - 1 Primary: receives all writes\n// - N Secondaries: replicate from primary\n// - Optional Arbiter: votes only, no data\n\n// Minimum: 3 members (or 2 + arbiter)\n// Recommended: 3 data-bearing members\n\n// Automatic failover:\n// 1. Primary becomes unavailable\n// 2. Secondaries hold election\n// 3. New primary elected\n// 4. Clients redirect automatically\n\n// Read preference\ndb.collection.find().readPref(\"primary\")        // default\ndb.collection.find().readPref(\"secondary\")      // read from secondary\ndb.collection.find().readPref(\"primaryPreferred\")\ndb.collection.find().readPref(\"secondaryPreferred\")\ndb.collection.find().readPref(\"nearest\")        // lowest latency\n\n// Write concern\ndb.collection.insertOne({...}, {writeConcern: {w: \"majority\"}})\n// w: 1 (primary only), \"majority\", number, or tag",
      "meaning": "Replica set คืออะไร?",
      "example": "Replica set is a group of MongoDB servers maintaining same data for high availability. One primary receives writes, secondaries replicate asynchronously. Automatic failover if primary fails. Read preference controls where to read (primary, secondary, nearest). Write concern controls acknowledgment level. Minimum 3 members recommended.",
      "exampleTranslation": "Replica set คือกลุ่ม MongoDB servers ที่รักษา data เดียวกันสำหรับ high availability Primary หนึ่งตัวรับ writes secondaries replicate แบบ asynchronous Automatic failover ถ้า primary fail Read preference ควบคุมว่าอ่านจากไหน (primary, secondary, nearest) Write concern ควบคุม acknowledgment level แนะนำขั้นต่ำ 3 members"
    },
    {
      "vocab": "What is sharding in MongoDB?",
      "pronunciation": "// Sharding: horizontal scaling across servers\n\n// Components:\n// - Shard: each holds subset of data (replica set)\n// - Config servers: store metadata\n// - mongos: query router\n\n// Shard key: determines data distribution\nsh.shardCollection(\"mydb.users\", {userId: \"hashed\"})\nsh.shardCollection(\"mydb.orders\", {customerId: 1, orderId: 1})\n\n// Shard key strategies:\n// - Hashed: even distribution, no range queries\n// - Ranged: range queries, risk of hotspots\n// - Compound: balance of both\n\n// Good shard key:\n// - High cardinality (many unique values)\n// - Even distribution\n// - Query isolation (queries target few shards)\n// - Not monotonically increasing\n\n// Check shard distribution\ndb.collection.getShardDistribution()",
      "meaning": "Sharding ใน MongoDB คืออะไร?",
      "example": "Sharding distributes data across multiple servers (shards) for horizontal scaling. Shard key determines which shard stores each document. Hashed keys give even distribution but no range queries. Ranged keys support ranges but may create hotspots. Choose key with high cardinality that matches query patterns. Cannot change shard key after creation.",
      "exampleTranslation": "Sharding กระจาย data ข้ามหลาย servers (shards) สำหรับ horizontal scaling Shard key กำหนดว่า shard ไหนเก็บแต่ละ document Hashed keys ให้การกระจายสม่ำเสมอแต่ไม่มี range queries Ranged keys รองรับ ranges แต่อาจสร้าง hotspots เลือก key ที่มี high cardinality ตรงกับ query patterns เปลี่ยน shard key หลังสร้างไม่ได้"
    },
    {
      "vocab": "What is the difference between find() and aggregate()?",
      "pronunciation": "// find() - simple queries\ndb.users.find(\n  {status: \"active\"},          // filter\n  {name: 1, email: 1, _id: 0}  // projection\n)\n.sort({createdAt: -1})\n.limit(10)\n.skip(20)\n\n// aggregate() - complex transformations\ndb.orders.aggregate([\n  {$match: {status: \"completed\"}},\n  {$group: {_id: \"$customerId\", total: {$sum: \"$amount\"}}},\n  {$lookup: {from: \"customers\", localField: \"_id\", foreignField: \"_id\", as: \"customer\"}},\n  {$unwind: \"$customer\"},\n  {$project: {customerName: \"$customer.name\", total: 1}},\n  {$sort: {total: -1}},\n  {$limit: 10}\n])\n\n// Use find() when:\n// - Simple filtering and projection\n// - No grouping or joins needed\n\n// Use aggregate() when:\n// - Grouping, summing, averaging\n// - Joining collections ($lookup)\n// - Complex transformations",
      "meaning": "find() และ aggregate() ต่างกันอย่างไร?",
      "example": "find() for simple queries: filtering, projection, sorting, pagination. Returns documents as-is. aggregate() for complex operations: grouping, joining, reshaping, computing. Pipeline of transformation stages. Use find() for basic CRUD reads. Use aggregate() for analytics, reports, joins, and any transformation beyond simple filtering.",
      "exampleTranslation": "find() สำหรับ queries ง่าย: filtering, projection, sorting, pagination Return documents ตามเดิม aggregate() สำหรับ operations ซับซ้อน: grouping, joining, reshaping, computing Pipeline ของ transformation stages ใช้ find() สำหรับ basic CRUD reads ใช้ aggregate() สำหรับ analytics, reports, joins และ transformation ใดๆ ที่เกินกว่า simple filtering"
    },
    {
      "vocab": "What is $expr and when to use it?",
      "pronunciation": "// $expr: use aggregation expressions in queries\n\n// Compare two fields in same document\ndb.inventory.find({\n  $expr: {$gt: [\"$quantity\", \"$reorderLevel\"]}\n})\n\n// With aggregation operators\ndb.orders.find({\n  $expr: {\n    $and: [\n      {$eq: [\"$status\", \"pending\"]},\n      {$lt: [\n        {$dateDiff: {\n          startDate: \"$createdAt\",\n          endDate: \"$$NOW\",\n          unit: \"hour\"\n        }},\n        24\n      ]}\n    ]\n  }\n})\n\n// In $match stage with variables\ndb.orders.aggregate([\n  {$lookup: {\n    from: \"products\",\n    let: {orderedQty: \"$quantity\"},\n    pipeline: [\n      {$match: {\n        $expr: {$gte: [\"$stock\", \"$$orderedQty\"]}\n      }}\n    ],\n    as: \"availableProducts\"\n  }}\n])",
      "meaning": "$expr คืออะไรและใช้เมื่อไหร่?",
      "example": "$expr allows aggregation expressions in query language. Use to: compare fields in same document, use aggregation operators in find(), access variables in $lookup pipeline. Prefix fields with $ and variables with $$. Essential for dynamic comparisons that standard query operators can't handle.",
      "exampleTranslation": "$expr อนุญาตให้ใช้ aggregation expressions ใน query language ใช้เพื่อ: compare fields ใน document เดียวกัน ใช้ aggregation operators ใน find() เข้าถึง variables ใน $lookup pipeline ใส่ prefix $ กับ fields และ $$ กับ variables จำเป็นสำหรับ dynamic comparisons ที่ standard query operators จัดการไม่ได้"
    },
    {
      "vocab": "What are write concerns and read concerns?",
      "pronunciation": "// Write Concern: acknowledgment level for writes\ndb.collection.insertOne(\n  {name: \"John\"},\n  {writeConcern: {w: \"majority\", j: true, wtimeout: 5000}}\n)\n\n// w options:\n// - 0: no acknowledgment (fire and forget)\n// - 1: primary acknowledged (default)\n// - \"majority\": majority of replica set\n// - n: specific number of nodes\n\n// j: true = wait for journal write (durable)\n// wtimeout: max wait time in ms\n\n// Read Concern: consistency level for reads\ndb.collection.find().readConcern(\"local\")      // default, may read uncommitted\ndb.collection.find().readConcern(\"majority\")  // committed to majority\ndb.collection.find().readConcern(\"linearizable\") // strongest, slowest\ndb.collection.find().readConcern(\"snapshot\")  // for transactions\n\n// Causal consistency\nconst session = client.startSession({causalConsistency: true})",
      "meaning": "Write concerns และ read concerns คืออะไร?",
      "example": "Write concern controls acknowledgment before returning success. w:1 (primary only), w:\"majority\" (safer), j:true (journaled). Higher = more durable, slower. Read concern controls consistency: \"local\" (may see uncommitted), \"majority\" (committed data), \"linearizable\" (strongest). Match write and read concerns for desired consistency level.",
      "exampleTranslation": "Write concern ควบคุม acknowledgment ก่อน return success w:1 (primary เท่านั้น), w:\"majority\" (ปลอดภัยกว่า), j:true (journaled) สูงกว่า = durable กว่า ช้ากว่า Read concern ควบคุม consistency: \"local\" (อาจเห็น uncommitted), \"majority\" (committed data), \"linearizable\" (แข็งแรงที่สุด) Match write และ read concerns สำหรับ consistency level ที่ต้องการ"
    },
    {
      "vocab": "What is the $facet stage?",
      "pronunciation": "// $facet: multiple aggregation pipelines in one\ndb.products.aggregate([\n  {$match: {status: \"active\"}},\n  {$facet: {\n    // Pipeline 1: Category breakdown\n    byCategory: [\n      {$group: {_id: \"$category\", count: {$sum: 1}}},\n      {$sort: {count: -1}}\n    ],\n    \n    // Pipeline 2: Price ranges\n    byPriceRange: [\n      {$bucket: {\n        groupBy: \"$price\",\n        boundaries: [0, 50, 100, 500, Infinity],\n        default: \"Other\",\n        output: {count: {$sum: 1}}\n      }}\n    ],\n    \n    // Pipeline 3: Metadata\n    metadata: [\n      {$count: \"total\"},\n    ],\n    \n    // Pipeline 4: Sample products\n    samples: [\n      {$sample: {size: 5}},\n      {$project: {name: 1, price: 1}}\n    ]\n  }}\n])",
      "meaning": "$facet stage คืออะไร?",
      "example": "$facet runs multiple aggregation pipelines on same input documents in single stage. Each sub-pipeline produces independent results. Output is document with field per facet. Great for: search results with filters, dashboards with multiple metrics, pagination with total count. Each facet processes full input independently.",
      "exampleTranslation": "$facet รันหลาย aggregation pipelines บน input documents เดียวกันใน stage เดียว แต่ละ sub-pipeline สร้างผลลัพธ์อิสระ Output คือ document ที่มี field ต่อ facet ดีสำหรับ: search results พร้อม filters, dashboards ที่มี metrics หลายตัว, pagination พร้อม total count แต่ละ facet process input ทั้งหมดอย่างอิสระ"
    },
    {
      "vocab": "What is Change Streams?",
      "pronunciation": "// Watch for changes in real-time\nconst changeStream = db.collection.watch();\n\nchangeStream.on('change', (change) => {\n  console.log(change);\n  // {\n  //   operationType: 'insert' | 'update' | 'delete' | 'replace',\n  //   fullDocument: {...},\n  //   documentKey: {_id: ...},\n  //   updateDescription: {updatedFields: {...}, removedFields: []}\n  // }\n});\n\n// Watch with filter\nconst pipeline = [\n  {$match: {\n    'operationType': {$in: ['insert', 'update']},\n    'fullDocument.status': 'active'\n  }}\n];\nconst changeStream = db.collection.watch(pipeline);\n\n// Resume after disconnect\nconst resumeToken = change._id;\nconst changeStream = db.collection.watch([], {resumeAfter: resumeToken});\n\n// Watch entire database or deployment\ndb.watch()        // database\nclient.watch()    // deployment",
      "meaning": "Change Streams คืออะไร?",
      "example": "Change Streams allow applications to watch for real-time data changes. Subscribe to insert, update, delete, replace events. Can filter changes with aggregation pipeline. Resume token allows continuing after disconnection. Requires replica set. Great for: real-time sync, notifications, event-driven architectures, cache invalidation.",
      "exampleTranslation": "Change Streams อนุญาตให้ applications watch data changes แบบ real-time Subscribe กับ insert, update, delete, replace events Filter changes ด้วย aggregation pipeline ได้ Resume token อนุญาตให้ทำต่อหลัง disconnection ต้องมี replica set ดีสำหรับ: real-time sync, notifications, event-driven architectures, cache invalidation"
    },
    {
      "vocab": "What is the $graphLookup stage?",
      "pronunciation": "// $graphLookup: recursive search for graph/tree data\ndb.employees.aggregate([\n  {$match: {name: \"CEO\"}},\n  {$graphLookup: {\n    from: \"employees\",\n    startWith: \"$_id\",\n    connectFromField: \"_id\",\n    connectToField: \"managerId\",\n    as: \"allReports\",\n    maxDepth: 5,\n    depthField: \"level\"\n  }}\n])\n\n// Returns:\n{\n  name: \"CEO\",\n  allReports: [\n    {name: \"VP\", level: 0},\n    {name: \"Director\", level: 1},\n    {name: \"Manager\", level: 2},\n    {name: \"Employee\", level: 3}\n  ]\n}\n\n// Options:\n// from: collection to search\n// startWith: starting value(s)\n// connectFromField: field value to match\n// connectToField: field to match against\n// as: output array field\n// maxDepth: limit recursion depth\n// depthField: add depth number to results\n// restrictSearchWithMatch: filter during search",
      "meaning": "$graphLookup stage คืออะไร?",
      "example": "$graphLookup performs recursive search on collection, traversing graph or tree structures. Starts with value and follows connections repeatedly. Use for: org charts, category trees, social networks, bill of materials. Set maxDepth to limit recursion. depthField adds level number to each result. More efficient than multiple $lookups.",
      "exampleTranslation": "$graphLookup ทำ recursive search บน collection traverse graph หรือ tree structures เริ่มด้วยค่าและตาม connections ซ้ำๆ ใช้สำหรับ: org charts, category trees, social networks, bill of materials Set maxDepth เพื่อจำกัด recursion depthField เพิ่ม level number ให้แต่ละ result มีประสิทธิภาพกว่าหลาย $lookups"
    },
    {
      "vocab": "What is Atlas Search?",
      "pronunciation": "// Atlas Search: full-text search powered by Lucene\n\n// Create search index (Atlas UI or API)\n{\n  \"mappings\": {\n    \"dynamic\": false,\n    \"fields\": {\n      \"title\": {\"type\": \"string\", \"analyzer\": \"lucene.standard\"},\n      \"content\": {\"type\": \"string\", \"analyzer\": \"lucene.english\"}\n    }\n  }\n}\n\n// $search stage in aggregation\ndb.articles.aggregate([\n  {$search: {\n    index: \"default\",\n    text: {\n      query: \"mongodb tutorial\",\n      path: [\"title\", \"content\"],\n      fuzzy: {maxEdits: 1}\n    },\n    highlight: {path: [\"content\"]}\n  }},\n  {$project: {\n    title: 1,\n    score: {$meta: \"searchScore\"},\n    highlights: {$meta: \"searchHighlights\"}\n  }},\n  {$limit: 10}\n])\n\n// Autocomplete\n{$search: {\n  autocomplete: {\n    query: \"mong\",\n    path: \"title\"\n  }\n}}",
      "meaning": "Atlas Search คืออะไร?",
      "example": "Atlas Search is MongoDB Atlas's full-text search powered by Apache Lucene. Define search indexes with field mappings and analyzers. Use $search stage in aggregation. Features: fuzzy matching, highlighting, autocomplete, faceting, scoring. More powerful than $text index. Only available in Atlas (cloud) or Atlas Search on-prem.",
      "exampleTranslation": "Atlas Search คือ full-text search ของ MongoDB Atlas powered by Apache Lucene กำหนด search indexes ด้วย field mappings และ analyzers ใช้ $search stage ใน aggregation Features: fuzzy matching, highlighting, autocomplete, faceting, scoring มีพลังมากกว่า $text index มีเฉพาะใน Atlas (cloud) หรือ Atlas Search on-prem"
    },
    {
      "vocab": "What is the difference between $push and $addToSet?",
      "pronunciation": "// $push: always adds to array (allows duplicates)\ndb.users.updateOne(\n  {_id: 1},\n  {$push: {tags: \"mongodb\"}}\n)\n// Before: {tags: [\"javascript\"]}\n// After: {tags: [\"javascript\", \"mongodb\"]}\n\ndb.users.updateOne(\n  {_id: 1},\n  {$push: {tags: \"mongodb\"}}\n)\n// After: {tags: [\"javascript\", \"mongodb\", \"mongodb\"]}  // duplicate!\n\n// $addToSet: only adds if not exists\ndb.users.updateOne(\n  {_id: 1},\n  {$addToSet: {tags: \"mongodb\"}}\n)\n// Before: {tags: [\"javascript\", \"mongodb\"]}\n// After: {tags: [\"javascript\", \"mongodb\"]}  // no duplicate\n\n// $push with modifiers\n{$push: {scores: {$each: [85, 90], $sort: -1, $slice: 10}}}\n// Add multiple, sort descending, keep top 10\n\n// $addToSet with $each\n{$addToSet: {tags: {$each: [\"a\", \"b\", \"c\"]}}}",
      "meaning": "$push และ $addToSet ต่างกันอย่างไร?",
      "example": "$push always appends to array, allowing duplicates. $addToSet only adds if value doesn't exist (set behavior). Both support $each for multiple values. $push also supports $sort, $slice, $position modifiers. Use $addToSet for unique collections like tags. Use $push for ordered logs or when duplicates are allowed.",
      "exampleTranslation": "$push append ไปยัง array เสมอ อนุญาตให้ duplicate $addToSet เพิ่มเฉพาะเมื่อค่าไม่มีอยู่ (set behavior) ทั้งคู่รองรับ $each สำหรับหลายค่า $push ยังรองรับ $sort, $slice, $position modifiers ใช้ $addToSet สำหรับ unique collections เช่น tags ใช้ $push สำหรับ ordered logs หรือเมื่ออนุญาตให้ duplicates"
    },
    {
      "vocab": "What is the $unwind stage?",
      "pronunciation": "// $unwind: deconstruct array into multiple documents\n\n// Input document\n{name: \"John\", hobbies: [\"reading\", \"gaming\", \"hiking\"]}\n\n// After $unwind: {$unwind: \"$hobbies\"}\n{name: \"John\", hobbies: \"reading\"}\n{name: \"John\", hobbies: \"gaming\"}\n{name: \"John\", hobbies: \"hiking\"}\n\n// Preserve null/empty arrays\n{$unwind: {\n  path: \"$hobbies\",\n  preserveNullAndEmptyArrays: true\n}}\n// Without: documents with empty/missing arrays are excluded\n\n// Include array index\n{$unwind: {\n  path: \"$items\",\n  includeArrayIndex: \"itemIndex\"\n}}\n// Output includes: {itemIndex: 0}, {itemIndex: 1}, ...\n\n// Common pattern: unwind, process, group back\ndb.orders.aggregate([\n  {$unwind: \"$items\"},\n  {$group: {_id: \"$items.productId\", totalQty: {$sum: \"$items.quantity\"}}}\n])",
      "meaning": "$unwind stage คืออะไร?",
      "example": "$unwind deconstructs array field, creating document per element. Original document is duplicated with one array value each. By default, excludes documents with null/empty arrays - use preserveNullAndEmptyArrays to include them. includeArrayIndex adds position number. Common pattern: unwind -> process -> group back together.",
      "exampleTranslation": "$unwind deconstruct array field สร้าง document ต่อ element Document ดั้งเดิมถูก duplicate กับค่า array หนึ่งตัวแต่ละ By default ไม่รวม documents ที่มี null/empty arrays - ใช้ preserveNullAndEmptyArrays เพื่อรวมมัน includeArrayIndex เพิ่ม position number Pattern ที่ใช้บ่อย: unwind -> process -> group กลับมา"
    },
    {
      "vocab": "What is findAndModify vs updateOne?",
      "pronunciation": "// updateOne: update and return result info\nconst result = await db.users.updateOne(\n  {_id: 1},\n  {$inc: {balance: -100}}\n);\n// result: {matchedCount: 1, modifiedCount: 1}\n// Does NOT return the document\n\n// findOneAndUpdate: update and return document\nconst doc = await db.users.findOneAndUpdate(\n  {_id: 1},\n  {$inc: {balance: -100}},\n  {returnDocument: \"after\"}  // or \"before\"\n);\n// Returns the updated document itself\n\n// findOneAndDelete: delete and return document\nconst deleted = await db.users.findOneAndDelete({_id: 1});\n\n// findOneAndReplace: replace and return document\nconst replaced = await db.users.findOneAndReplace(\n  {_id: 1},\n  {name: \"New\", status: \"active\"}\n);\n\n// Atomic: great for queues, counters\nconst job = await db.jobs.findOneAndUpdate(\n  {status: \"pending\"},\n  {$set: {status: \"processing\", worker: workerId}},\n  {sort: {priority: -1}, returnDocument: \"after\"}\n);",
      "meaning": "findAndModify vs updateOne ต่างกันอย่างไร?",
      "example": "updateOne modifies and returns operation stats (matched/modified count). findOneAndUpdate modifies and returns the document itself. Use returnDocument: \"after\" for updated version, \"before\" for original. findOneAndUpdate is atomic - perfect for job queues, counters, and when you need the document value. Slightly slower than updateOne.",
      "exampleTranslation": "updateOne modify และ return operation stats (matched/modified count) findOneAndUpdate modify และ return document เอง ใช้ returnDocument: \"after\" สำหรับ updated version \"before\" สำหรับ original findOneAndUpdate เป็น atomic - เหมาะสำหรับ job queues, counters และเมื่อต้องการค่า document ช้ากว่า updateOne เล็กน้อย"
    },
    {
      "vocab": "What is the $merge stage?",
      "pronunciation": "// $merge: write aggregation results to collection\ndb.orders.aggregate([\n  {$group: {\n    _id: {year: {$year: \"$date\"}, month: {$month: \"$date\"}},\n    totalSales: {$sum: \"$amount\"},\n    orderCount: {$sum: 1}\n  }},\n  {$merge: {\n    into: \"monthlySales\",\n    on: \"_id\",                    // match field\n    whenMatched: \"replace\",       // replace | merge | keepExisting | fail | pipeline\n    whenNotMatched: \"insert\"      // insert | discard | fail\n  }}\n])\n\n// whenMatched options:\n// \"replace\": replace entire document\n// \"merge\": merge with existing (like $set)\n// \"keepExisting\": keep existing document\n// \"fail\": throw error\n// pipeline: custom update pipeline\n\n// $out: simpler, replaces entire collection\n{$out: \"outputCollection\"}\n// Warning: drops existing collection first!",
      "meaning": "$merge stage คืออะไร?",
      "example": "$merge writes aggregation results to collection with control over matching and conflicts. Can insert new, update existing, or both. whenMatched controls update behavior, whenNotMatched controls insert. $out is simpler but replaces entire collection. $merge is incremental - better for updating existing data. Great for materialized views.",
      "exampleTranslation": "$merge เขียน aggregation results ไปยัง collection พร้อมควบคุม matching และ conflicts Insert ใหม่ update existing หรือทั้งคู่ได้ whenMatched ควบคุม update behavior whenNotMatched ควบคุม insert $out ง่ายกว่าแต่ replace ทั้ง collection $merge เป็น incremental - ดีกว่าสำหรับ updating existing data ดีสำหรับ materialized views"
    },
    {
      "vocab": "What is capped collection?",
      "pronunciation": "// Capped collection: fixed-size, FIFO\ndb.createCollection(\"logs\", {\n  capped: true,\n  size: 10485760,     // 10MB max size\n  max: 5000           // max 5000 documents (optional)\n})\n\n// Characteristics:\n// - Fixed size, automatically removes oldest when full\n// - Insertion order preserved\n// - Cannot delete individual documents\n// - Cannot shard\n// - Very fast writes (no index maintenance for _id)\n\n// Check if capped\ndb.logs.isCapped()\n\n// Convert existing to capped\ndb.runCommand({convertToCapped: \"mycollection\", size: 10485760})\n\n// Use cases:\n// - Log storage\n// - Caching\n// - Rolling metrics\n// - Real-time data (with tailable cursors)\n\n// Tailable cursor: like tail -f\nconst cursor = db.logs.find().tailable().awaitData();\nwhile (cursor.hasNext()) {\n  console.log(cursor.next());\n}",
      "meaning": "Capped collection คืออะไร?",
      "example": "Capped collections have fixed size and maintain insertion order. When full, oldest documents automatically removed (FIFO). Very fast writes, cannot delete individuals or shard. Use for: logs, metrics, cache, rolling data. Tailable cursors allow real-time streaming like 'tail -f'. Set size in bytes, optionally max document count.",
      "exampleTranslation": "Capped collections มี fixed size และรักษา insertion order เมื่อเต็ม documents เก่าสุดถูกลบอัตโนมัติ (FIFO) เขียนเร็วมาก delete แต่ละตัวหรือ shard ไม่ได้ ใช้สำหรับ: logs, metrics, cache, rolling data Tailable cursors อนุญาตให้ real-time streaming เหมือน 'tail -f' Set size เป็น bytes เลือก max document count ได้"
    },
    {
      "vocab": "What is schema validation?",
      "pronunciation": "// Create collection with validation\ndb.createCollection(\"users\", {\n  validator: {\n    $jsonSchema: {\n      bsonType: \"object\",\n      required: [\"name\", \"email\"],\n      properties: {\n        name: {\n          bsonType: \"string\",\n          description: \"must be a string\"\n        },\n        email: {\n          bsonType: \"string\",\n          pattern: \"^.+@.+$\"\n        },\n        age: {\n          bsonType: \"int\",\n          minimum: 0,\n          maximum: 150\n        },\n        status: {\n          enum: [\"active\", \"inactive\", \"pending\"]\n        }\n      }\n    }\n  },\n  validationLevel: \"strict\",    // strict | moderate\n  validationAction: \"error\"     // error | warn\n})\n\n// Modify validation\ndb.runCommand({\n  collMod: \"users\",\n  validator: {$jsonSchema: {...}}\n})",
      "meaning": "Schema validation คืออะไร?",
      "example": "Schema validation enforces document structure using $jsonSchema. Define required fields, types, patterns, ranges, enums. validationLevel: 'strict' (all writes) or 'moderate' (only inserts and valid updates). validationAction: 'error' (reject) or 'warn' (allow but log). Add validation to existing collections with collMod. Provides data integrity without losing MongoDB flexibility.",
      "exampleTranslation": "Schema validation บังคับ document structure โดยใช้ $jsonSchema กำหนด required fields, types, patterns, ranges, enums validationLevel: 'strict' (ทุก writes) หรือ 'moderate' (เฉพาะ inserts และ valid updates) validationAction: 'error' (reject) หรือ 'warn' (อนุญาตแต่ log) เพิ่ม validation ให้ existing collections ด้วย collMod ให้ data integrity โดยไม่เสีย MongoDB flexibility"
    },
    {
      "vocab": "What is bulkWrite?",
      "pronunciation": "// bulkWrite: multiple operations in single request\nconst result = await db.collection.bulkWrite([\n  {\n    insertOne: {document: {name: \"Alice\"}}\n  },\n  {\n    updateOne: {\n      filter: {name: \"Bob\"},\n      update: {$set: {status: \"active\"}}\n    }\n  },\n  {\n    updateMany: {\n      filter: {status: \"pending\"},\n      update: {$set: {status: \"processed\"}}\n    }\n  },\n  {\n    deleteOne: {\n      filter: {name: \"Charlie\"}\n    }\n  },\n  {\n    replaceOne: {\n      filter: {name: \"Dave\"},\n      replacement: {name: \"Dave\", age: 30}\n    }\n  }\n], {ordered: false})  // parallel execution\n\n// Result\n{\n  insertedCount: 1,\n  matchedCount: 5,\n  modifiedCount: 4,\n  deletedCount: 1,\n  upsertedCount: 0\n}\n\n// ordered: true (default) - stop on first error\n// ordered: false - continue on errors, parallel execution",
      "meaning": "bulkWrite คืออะไร?",
      "example": "bulkWrite executes multiple write operations in single request. Mix of insert, update, delete, replace. ordered:true stops on first error (sequential). ordered:false continues on errors and may parallelize (faster). Returns combined result counts. Much more efficient than individual operations for batch processing. Max 100,000 operations per batch.",
      "exampleTranslation": "bulkWrite execute หลาย write operations ใน single request ผสม insert, update, delete, replace ordered:true หยุดที่ error แรก (sequential) ordered:false ทำต่อเมื่อมี errors และอาจ parallelize (เร็วกว่า) Return combined result counts มีประสิทธิภาพกว่า individual operations มากสำหรับ batch processing Max 100,000 operations ต่อ batch"
    },
    {
      "vocab": "What is TTL index?",
      "pronunciation": "// TTL index: automatically delete expired documents\ndb.sessions.createIndex(\n  {createdAt: 1},\n  {expireAfterSeconds: 3600}  // 1 hour\n)\n\n// Documents deleted after createdAt + 3600 seconds\n// Background task runs every 60 seconds\n\n// Expire at specific time\ndb.events.createIndex(\n  {expireAt: 1},\n  {expireAfterSeconds: 0}  // expire at the date value itself\n)\n\ndb.events.insertOne({\n  event: \"sale\",\n  expireAt: new Date(\"2024-12-31\")  // expires on this date\n})\n\n// Limitations:\n// - Only works on single date field\n// - Cannot be compound index\n// - Background deletion (not instant)\n// - ~60 second check interval\n\n// Use cases:\n// - Session expiration\n// - Temporary data cleanup\n// - Log rotation\n// - Cache expiration",
      "meaning": "TTL index คืออะไร?",
      "example": "TTL (Time-To-Live) index automatically deletes documents after specified time. Set expireAfterSeconds from date field value. Use 0 with date field containing exact expiration time. Background thread checks every ~60 seconds. Only works on single date field. Perfect for sessions, temporary data, logs, and cache entries that should auto-expire.",
      "exampleTranslation": "TTL (Time-To-Live) index ลบ documents อัตโนมัติหลังเวลาที่กำหนด Set expireAfterSeconds จากค่า date field ใช้ 0 กับ date field ที่มี exact expiration time Background thread check ทุก ~60 วินาที ทำงานบน single date field เท่านั้น เหมาะสำหรับ sessions, temporary data, logs และ cache entries ที่ควร auto-expire"
    },
    {
      "vocab": "What are MongoDB best practices?",
      "pronunciation": "// Schema Design:\n// - Design for your queries, not data\n// - Embed when data is accessed together\n// - Reference when data grows unbounded\n// - Avoid deep nesting (16 levels max)\n\n// Indexing:\n// - Index fields you query on\n// - Use compound indexes following ESR\n// - Use explain() to verify index usage\n// - Limit indexes (each slows writes)\n\n// Queries:\n// - Use projection to return only needed fields\n// - Avoid $where and JavaScript in queries\n// - Use $limit early in aggregation\n// - Avoid large $in arrays\n\n// Operations:\n// - Use bulk operations for multiple writes\n// - Set appropriate write/read concerns\n// - Use connection pooling\n// - Handle timeouts and retries\n\n// Monitoring:\n// - Monitor slow queries (profiler)\n// - Watch for collection scans\n// - Track memory and connection usage",
      "meaning": "MongoDB best practices มีอะไรบ้าง?",
      "example": "Schema: design for queries, embed related data, reference for unbounded growth. Indexing: follow ESR rule, verify with explain(), don't over-index. Queries: use projection, avoid JavaScript in queries, limit early. Operations: bulk writes, appropriate concerns, connection pooling. Monitor: slow queries, collection scans, resource usage.",
      "exampleTranslation": "Schema: ออกแบบสำหรับ queries embed related data reference สำหรับ unbounded growth Indexing: ทำตาม ESR rule verify ด้วย explain() อย่า over-index Queries: ใช้ projection หลีกเลี่ยง JavaScript ใน queries limit ก่อน Operations: bulk writes, concerns ที่เหมาะสม connection pooling Monitor: slow queries, collection scans, resource usage"
    },
    {
      "vocab": "What is MongoDB security best practices?",
      "pronunciation": "// Authentication\nuse admin\ndb.createUser({\n  user: \"appUser\",\n  pwd: \"securePassword\",\n  roles: [{role: \"readWrite\", db: \"myapp\"}]\n})\n\n// Built-in roles:\n// read, readWrite, dbAdmin, userAdmin\n// clusterAdmin, backup, restore\n// root (superuser)\n\n// Enable authentication\n// mongod.conf:\nsecurity:\n  authorization: enabled\n\n// Network security\nnet:\n  bindIp: 127.0.0.1,10.0.0.1   // specific IPs\n  tls:\n    mode: requireTLS\n    certificateKeyFile: /path/to/cert.pem\n\n// Field-level encryption\n// Client-side encryption for sensitive fields\n\n// Auditing (Enterprise)\nauditLog:\n  destination: file\n  format: JSON\n  path: /var/log/mongodb/audit.json\n\n// Best practices:\n// - Principle of least privilege\n// - Never expose to public internet\n// - Enable TLS/SSL\n// - Regular security audits",
      "meaning": "MongoDB security best practices มีอะไรบ้าง?",
      "example": "Enable authentication with strong passwords. Use role-based access control (RBAC) with least privilege. Bind to specific IPs, never 0.0.0.0 in production. Enable TLS/SSL for encryption in transit. Use client-side field level encryption for sensitive data. Keep MongoDB and drivers updated. Audit access in enterprise.",
      "exampleTranslation": "Enable authentication ด้วย passwords ที่แข็งแรง ใช้ role-based access control (RBAC) ด้วย least privilege Bind กับ specific IPs ไม่ใช่ 0.0.0.0 ใน production Enable TLS/SSL สำหรับ encryption in transit ใช้ client-side field level encryption สำหรับ sensitive data Keep MongoDB และ drivers updated Audit access ใน enterprise"
    }
  ]
}
